<!--
参考：https://threejs.org/manual/#zh/picking
new THREE.Raycaster().setFromCamera ( coords : Vector2, camera : Camera )
coords —— 在标准化设备坐标中鼠标的二维坐标 —— X分量与Y分量应当在-1到1之间。注意：此鼠标的二维坐标需要转为在3d画布中的二维坐标，即【3dy = canvas.height-2dy】
camera —— 射线所来源的摄像机。

使用一个新的原点和方向来更新射线。


为了完成GPU拾取，对每一个对象使用唯一的颜色进行离屏渲染。然后，检查鼠标位置关联的像素的颜色。这个颜色就能告诉我们哪个对象被选中。
每个对象会被绘制两次，一次用于观看，一次用于拾取。

-->
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>鼠标拾取 - 光线投射Raycaster</title>
    <style>
        * {
            margin: 0;
            padding: 0;
        }

        html, body {
            height: 100%;
            margin: 0;
        }
        #c {
            width: 100%;
            height: 100%;
            display: block;
        }


    </style>
    <!-- <script type="text/javascript" src="js/three.min.js"></script> -->
</head>
<body>
<canvas id="c"></canvas>
<!-- Remove this when import maps will be widely supported -->
<script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>
<script type="importmap">
			{
				"imports": {
					"three": "./build/three.module.js"
				}
			}
</script>
<script type="module">
    import * as THREE from 'three';
    import {GUI} from './js/lil-gui.module.min.js';
    import {OrbitControls} from './jsm/controls/OrbitControls.js'; // 允许相机环绕目标的控制器
    import {TrackballControls} from './jsm/controls/TrackballControls.js'; // TrackballControls 与 OrbitControls 相类似。然而，它不能恒定保持摄像机的up向量。 这意味着，如果摄像机绕过“北极”和“南极”，则不会翻转以保持“右侧朝上”。

    function main() {
        const canvas = document.querySelector('#c');
        const renderer = new THREE.WebGLRenderer({canvas});

        const fov = 60;
        const aspect = 2;  // the canvas default
        const near = 0.1;
        const far = 200;
        const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
        camera.position.z = 30;

        const scene = new THREE.Scene();// 一个使用正常的网格对象填充的场景
        scene.background = new THREE.Color('white');
        const pickingScene = new THREE.Scene(); // 使用“拾取材质”的网格对象填充的场景
        pickingScene.background = new THREE.Color(0);

        // helper
        scene.add(new THREE.AxesHelper(250))

        // controls
        const controls = new OrbitControls(camera, renderer.domElement);
        controls.update()

        // put the camera on a pole (parent it to an object)
        // so we can spin the pole to move the camera around the scene
        const cameraPole = new THREE.Object3D();
        scene.add(cameraPole);
        cameraPole.add(camera);

        //        light
        {
            const color = 0xFFFFFF;
            const intensity = 1;
            const light = new THREE.DirectionalLight(color, intensity);
            light.position.set(-1, 2, 4);
            camera.add(light); // 把光源也绑定到摄像机上，这样光源就会随着摄像机移动。
        }

        const boxWidth = 1;
        const boxHeight = 1;
        const boxDepth = 1;
        const geometry = new THREE.BoxGeometry(boxWidth, boxHeight, boxDepth); // 一盒多用

        function rand(min, max) {
            if (max === undefined) {
                max = min;
                min = 0;
            }
            return min + (max - min) * Math.random();
        }

        // 生成随机色
        function randomColor() {
            return `hsl(${rand(360) | 0}, ${rand(50, 100) | 0}%, 50%)`;
        }

        const loader = new THREE.TextureLoader();
        const texture = loader.load('./resources/images/frame.png');

        // 生成100个立方体，每个立方体的颜色，位置，朝向，缩放都随机。
        // 然后，对于在主场景中的每一个立方体，在 pickingScene 中，在同样的位置，创建一个与原立方体相似的，相关联的“可拾取立方体”，用对象的id生成颜色值，去设置对象的材质。
        const idToObject = {};
        const numObjects = 100;
        for (let i = 0; i < numObjects; ++i) {
            const id = i + 1;
            const material = new THREE.MeshPhongMaterial({
                color: randomColor(),
                map: texture,
                transparent: true,
                side: THREE.DoubleSide,
                alphaTest: 0.5,
            });

            const cube = new THREE.Mesh(geometry, material);
            scene.add(cube);
            idToObject[id] = cube; // 记录id与物体间的信息，保证可通过id找到物体

            cube.position.set(rand(-20, 20), rand(-20, 20), rand(-20, 20));
            cube.rotation.set(rand(Math.PI), rand(Math.PI), 0);
            cube.scale.set(rand(3, 6), rand(3, 6), rand(3, 6));

            // 另外一个使用“拾取材质”的网格对象填充
            /*
             注意到，此时，我们利用 MeshPhongMaterial 创建材质，使用id生成颜色，设置到它的emissive属性，color 和 specular属性设置为0，设置 alphaTest 属性，只渲染纹理的alpha值大于该属性值的部分，还需要将blending 设置为 NoBlending，这样alpha通道不会作用到id生成色

             注意到，利用 MeshPhongMaterial 可能并不是最优的解决方案，因为，在绘制拾取场景时，仍然需要计算所有的光线，尽管我们不需要这些计算。一个更优的方案是使用自定义的着色器，只为纹理alpha值大于 alphaTest 属性值的部分，输出id生成色
            */
            const pickingMaterial = new THREE.MeshPhongMaterial({
                emissive: new THREE.Color(id), // 用对象的id生成颜色值，去设置对象的材质
                color: new THREE.Color(0, 0, 0),
                specular: new THREE.Color(0, 0, 0), // 材质的高光颜色
                map: texture,
                transparent: true,
                side: THREE.DoubleSide,
                alphaTest: 0.5,
                blending: THREE.NoBlending,
            });
            const pickingCube = new THREE.Mesh(geometry, pickingMaterial);
            pickingScene.add(pickingCube);// 添加到“拾取用”场景
            pickingCube.position.copy(cube.position); // 复制上面的位置、朝向、缩放，保证一模一样
            pickingCube.rotation.copy(cube.rotation);
            pickingCube.scale.copy(cube.scale);
        }

        function resizeRendererToDisplaySize(renderer) {
            const canvas = renderer.domElement;
            const width = canvas.clientWidth;
            const height = canvas.clientHeight;
            const needResize = canvas.width !== width || canvas.height !== height;
            if (needResize) {
                renderer.setSize(width, height, false);
            }
            return needResize;
        }

        // 管理拾取操作的类
        class GPUPickHelper {
            constructor() {
                // create a 1x1 pixel render target
                // 因为拾取时我们只需读取1px，所以我们可以设置摄像机，只绘制1px，通过 PerspectiveCamera.setViewOffset 方法，可以告诉THREE.js 计算出一个摄像机 只呈现一个大矩形的一个很小的部分。这应该能节省一些运行时间。
                this.pickingTexture = new THREE.WebGLRenderTarget(1, 1); // 这里使用了 WebGLRenderTarget，如同我们在 多个渲染目标中介绍的一样，此处，我们的渲染目标只有1像素的尺寸，1×1。
                this.pixelBuffer = new Uint8Array(4);
                this.pickedObject = null;
                this.pickedObjectSavedColor = 0;
            }
            pick(cssPosition, scene, camera, time) {
                const {pickingTexture, pixelBuffer} = this;

                // restore the color if there is a picked object 恢复上一个被拾取对象的颜色
                if (this.pickedObject) {
                    this.pickedObject.material.emissive.setHex(this.pickedObjectSavedColor);
                    this.pickedObject = undefined;
                }

                // 在鼠标处渲染1*1 px大小的渲染目标
                // set the view offset to represent just a single pixel under the mouse 将视图偏移设置为仅代表鼠标下的单个像素
                const pixelRatio = renderer.getPixelRatio(); // 返回当前使用设备像素比 DPR = 物理像素(设备像素) / 独立像素(CSS像素),物理像素可能出现高清屏，也就是多个物理像素来显示一个，当像素比为2:1时，使用4个物理像素显示1个CSS像素；
                // 可以将把更多的物理像素点压缩至一块屏幕里，从而达到更高的分辨率，并提高屏幕显示的细腻程度。也就是1px对应多个“物理像素”
//                console.log(pixelRatio, 55)
                /*
                 （视锥体）中设置偏移量
                 因为拾取时我们只需读取1px，所以我们可以设置摄像机，只绘制1px，通过 PerspectiveCamera.setViewOffset 方法，
                 可以告诉THREE.js 计算出一个摄像机 只呈现一个大矩形的一个很小的部分。这应该能节省一些运行时间。
                */
                camera.setViewOffset(
                    renderer.getContext().drawingBufferWidth,   // full width
                    renderer.getContext().drawingBufferHeight,  // full top
                    cssPosition.x * pixelRatio | 0,             // rect x
                    cssPosition.y * pixelRatio | 0,             // rect y
                    1,                                          // rect width
                    1,                                          // rect height
                );
                // render the scene - 针对的拾取场景
                renderer.setRenderTarget(pickingTexture);
                renderer.render(scene, camera);
                renderer.setRenderTarget(null);
                // clear the view offset so rendering returns to normal
                camera.clearViewOffset();
                //read the pixel - 将当前渲染目标中的像素数据读取到传入的缓冲区中
                renderer.readRenderTargetPixels(
                    pickingTexture,// 参数是WebGLRenderTarget类型
                    0,   // x
                    0,   // y
                    1,   // width
                    1,   // height
                    pixelBuffer); // pixelBuffer参数必须是Uint8Array

                const id =
                    (pixelBuffer[0] << 16) |
                    (pixelBuffer[1] <<  8) |
                    (pixelBuffer[2]      );
//                console.log(pixelBuffer,id)

                const intersectedObject = idToObject[id];
                if (intersectedObject) {
                    if(intersectedObject.type !== 'Mesh') return // 容错处理，这里只穿透物体
                    // pick the first object. It's the closest one
                    this.pickedObject = intersectedObject;
                    // save its color
                    this.pickedObjectSavedColor = this.pickedObject.material.emissive.getHex();
                    // set its emissive color to flashing red/yellow
                    this.pickedObject.material.emissive.setHex((time * 8) % 2 > 1 ? 0xFFFF00 : 0xFF0000);
                }
            }
        }

        const pickPosition = {x: 0, y: 0};
        const pickHelper = new GPUPickHelper();
        clearPickPosition();

        function render(time) {
            time *= 0.001;  // convert to seconds;

            // 解决拉伸问题和像素块问题
            if (resizeRendererToDisplaySize(renderer)) {
                const canvas = renderer.domElement;
                camera.aspect = canvas.clientWidth / canvas.clientHeight;
                camera.updateProjectionMatrix();
            }

            cameraPole.rotation.y = time * .1;  // 相机沿着y轴旋转

            pickHelper.pick(pickPosition, pickingScene, camera, time); // 这里是将 pickScene 传给helper,而不是scene。

            renderer.render(scene, camera);

            requestAnimationFrame(render);
        }
        requestAnimationFrame(render);

        // 下面是设置鼠标位置【需要转换到内容缓冲区里面的坐标】到变量，方便GPUPickHelper类使用

        // 获取相对于canvas的位置，这里因为canvas有两个尺寸，获取相对于canvas内容缓冲区的位置
        function getCanvasRelativePosition(event) {
            const rect = canvas.getBoundingClientRect();
            return {
                x: (event.clientX - rect.left) * canvas.width  / rect.width,
                y: (event.clientY - rect.top ) * canvas.height / rect.height,
            };
        }

        // 由于我们是从像素点拾取，而不是射线追踪，只需将代码修改为使用像素拾取方式，获取拾取位置。
        function setPickPosition(event) {
            const pos = getCanvasRelativePosition(event);
            pickPosition.x = pos.x;
            pickPosition.y = pos.y;
        }

        function clearPickPosition() {
            // unlike the mouse which always has a position 对于触屏，不像鼠标总是能有一个位置坐标
            // if the user stops touching the screen we want 如果用户不在触摸屏幕，我们希望停止拾取操作。
            // to stop picking. For now we just pick a value 因此，我们选取一个特别的值，表明什么都没选中
            // unlikely to pick something
            pickPosition.x = -100000;
            pickPosition.y = -100000;
        }

        // 当然，也可以在用户点击鼠标时，调用这个方法，这恐怕是最常见的应用场景。但是，在本范例中，不管在鼠标下方是什么，在每一帧中都会进行拾取操作,为此，需要跟踪鼠标的位置。
        // 这里添加事件监听
        window.addEventListener('mousemove', setPickPosition);
        window.addEventListener('mouseout', clearPickPosition);
        window.addEventListener('mouseleave', clearPickPosition);

        // 添加对移动设备的支持
        window.addEventListener('touchstart', (event) => {
            // prevent the window from scrolling
            event.preventDefault();
            setPickPosition(event.touches[0]);
        }, {passive: false});

        window.addEventListener('touchmove', (event) => {
            setPickPosition(event.touches[0]);
        });

        window.addEventListener('touchend', clearPickPosition);
    }

    main();

</script>
</body>
</html>
